{
  "model_name": "LSTM with Word2Vec",
  "architecture": {
    "embedding": {
      "type": "Word2Vec",
      "dimension": 300,
      "window": 5,
      "min_count": 2
    },
    "lstm": {
      "num_layers": 2,
      "hidden_dim": 128,
      "bidirectional": true,
      "dropout": 0.3
    },
    "total_parameters": 868867,
    "trainable_parameters": 868867
  },
  "training_config": {
    "optimizer": "Adam",
    "learning_rate": 0.001,
    "batch_size": 32,
    "epochs_trained": 14,
    "early_stopping": true,
    "patience": 3
  },
  "train_metrics": {
    "accuracy": 0.3657021276595745,
    "precision": 0.3458244312659934,
    "recall": 0.3657021276595745,
    "f1": 0.34960902509984293,
    "f1_macro": 0.32176580869146604
  },
  "val_metrics": {
    "accuracy": 0.7180796731358529,
    "precision": 0.7309628378974189,
    "recall": 0.7180796731358529,
    "f1": 0.7081172266973993,
    "f1_macro": 0.6881495425367844
  },
  "test_metrics": {
    "accuracy": 0.7031994554118448,
    "precision": 0.7151753229122606,
    "recall": 0.7031994554118448,
    "f1": 0.6899207800118496,
    "f1_macro": 0.665541221934289
  },
  "confusion_matrix": [
    [
      255,
      126,
      294
    ],
    [
      36,
      848,
      213
    ],
    [
      41,
      162,
      963
    ]
  ]
}